{
  "lr": 1e-3,
  "batch_size": 32,
  "num_epochs": 100,
  "init_lr": 1e-5,
  "warmup_steps": 50,
  "eval": {
    "checkpoint_every": 1,
    "prompts": ["a table"],
    "num_inference_steps": 10000,
    "guidance_scale": 1.0,
    "num_samples": 5
  }
}
